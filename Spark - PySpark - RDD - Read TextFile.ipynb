{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZPa3lIphJVC6NuoBrsmAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/pyspark/blob/main/Spark%20-%20PySpark%20-%20RDD%20-%20Read%20TextFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark - PySpark - RDD - Read TextFile**"
      ],
      "metadata": {
        "id": "0GYP2XryP3uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark core provides `textFile()` & `wholeTextFiles()` methods in SparkContext class which is used to read single and multiple text or csv files into a single Spark RDD. Using this method we can also read all files from a directory and files with a specific pattern."
      ],
      "metadata": {
        "id": "UvsASzeWP_7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S55L1bk5RNdC",
        "outputId": "2858f886-8c4f-4be2-b00a-a68f70bb09e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.8/dist-packages (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **textFile()**\n",
        "\n",
        "Read single or multiple text, csv files and returns a single Spark RDD [String]"
      ],
      "metadata": {
        "id": "oYuZ14woQw-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SSdK44E3Pwyp"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.master(\"local[1]\") \\\n",
        "        .appName(\"RDDTextFile\") \\\n",
        "        .getOrCreate()        "
      ],
      "metadata": {
        "id": "iITmNmpmRYbJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_text_file = spark.sparkContext.textFile(\"/content/files/*\")"
      ],
      "metadata": {
        "id": "9NFfx7cCRmas"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_text_file.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfRhzdv8UWJx",
        "outputId": "1b6ec453-5c41-4971-be23-4df9a48107a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Invalid, I', 'One, 1', 'Two, 2']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **wholeTextFiles()**\n",
        "\n",
        "Reads single or multiple files and returns a single `RDD[Tuple2[String, String]]`, where first value (_1) in a tuple is a file name and second value (_2) is content of the file."
      ],
      "metadata": {
        "id": "_C1K1eJyXqAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_whole_text_file = spark.sparkContext.wholeTextFiles(\"/content/files/*\")"
      ],
      "metadata": {
        "id": "nmBWFHNTX5C0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collection = rdd_whole_text_file.collect()"
      ],
      "metadata": {
        "id": "qCcO6ttiX-y0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in collection:\n",
        "  print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un_GRRYlYEoN",
        "outputId": "65d2edb9-8f05-4ac9-9c29-e76625adf851"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('file:/content/files/invalid.txt', 'Invalid, I')\n",
            "('file:/content/files/sample_1.txt', 'One, 1')\n",
            "('file:/content/files/sample_2.txt', 'Two, 2')\n"
          ]
        }
      ]
    }
  ]
}